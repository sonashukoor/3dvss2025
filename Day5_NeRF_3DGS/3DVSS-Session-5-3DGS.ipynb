{"cells":[{"cell_type":"markdown","source":["# 3D Gaussian Splatting\n","\n","**ðŸ”— Reference:** [graphdeco-inria/gaussian-splatting (GitHub)](https://github.com/graphdeco-inria/gaussian-splatting.git)"],"metadata":{"id":"rhCepuHdeZwY"}},{"cell_type":"markdown","source":["## Steps to Convert Your Custom Video into a 3D Scene using Gaussian Splatting\n","\n","Follow these steps to go from a regular video to a rendered 3D scene:\n","\n","---\n","\n","1. **Record a video**  \n","   Record a video of a subject (360Â° - go in a single circle around the subject) using your phone and transfer that video to your PC. Ensure that your video is in `.mp4` format. If it's not, convert it to `.mp4` using some online converter (ex: https://cloudconvert.com/).  \n","   **NOTE**: Make sure your video is at least of 20 seconds and covers all the angles for better 3D scene construction.\n","\n","1. On your local machine clone the Gaussian Splatting Repository\n","\n","   ```bash\n","   git clone https://github.com/graphdeco-inria/gaussian-splatting.git\n","   ```\n","\n","1. Inside the repository folder create a new folder named `dataset`. And inside `dataset` folder create another folder `input`.\n","\n","1. Put the video from Step 1 inside the `dataset` folder.\n","\n","1. **Get the duration of the video**  \n","   Run the following command in terminal at the location of the video to extract the duration:\n","\n","   ```bash\n","   ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 <PATH_TO_VIDEO_FILE>\n","   ```\n","   **NOTE**: You first need to install `ffmpeg` package for this command to run.\n","\n","1. **Calculate FPS**  \n","   Use the formula to calculate the value of Required FPS (Frames per second). This fps value describes the number of frames we need to sample from the video.\n","\n","   ```\n","   fps = <TOTAL_FRAMES_NEEDED> / <DURATION>\n","   ```\n","   **NOTE**: For the purpose of this demo we will keep the total number of frames to 100.\n","\n","1. **Convert video to image frames**\n","   Replace the frame rate as needed:\n","\n","   ```bash\n","   ffmpeg -i <PATH_TO_VIDEO> -vf \"fps=<TOTAL_FRAMES_NEEDED>/<DURATION>\" <PATH_TO_OUTPUT_FOLDER>/frame_%04d.png\n","   ```\n","   * Example: Let's say the duration of the video is 15 seconds, total frames required = 100, we are currently inside the dataset folder and the name of the video file is `input_video.mp4`, then the command in this case will be: `ffmpeg -i input_video.mp4 -vf \"fps=100/15\" input/frame_%04d.png`. (Note that the output of this command will serve as input to the colmap hence we are naming the directory as input and referring to it as `<PATH_TO_OUTPUT_FOLDER>` in the above command.\n","\n","   * After this you should get around 100 frames (need not be exactly 100) in your `input` folder.\n","\n","1. **Install COLMAP** (if not already installed)  \n","    Refer to: https://colmap.github.io/install.html  \n","    **Note**: The `convert.py` script of gaussian-splatting repo requires Colmap to run.\n","\n","1. **Convert images for training**\n","   Run the following script (from inside the repo folder: gaussian-splatting/):\n","\n","   ```bash\n","   python3 convert.py -s dataset\n","   ```\n","   * It will take around **5-6 minutes to run** based on the number of frames.\n","\n","   * This script will run COLMAP and output camera aligned images (NeRF/GS compatible format) along with camera parameters.\n","\n","   * After executing the script the structure of `dataset` folder should look like this:\n","   ```text\n","   .\n","â”œâ”€â”€ distorted\n","â”‚Â Â  â”œâ”€â”€ database.db\n","â”‚Â Â  â””â”€â”€ sparse\n","â”‚Â Â      â””â”€â”€ 0\n","â”‚Â Â          â”œâ”€â”€ cameras.bin\n","â”‚Â Â          â”œâ”€â”€ images.bin\n","â”‚Â Â          â”œâ”€â”€ points3D.bin\n","â”‚Â Â          â””â”€â”€ project.ini\n","â”œâ”€â”€ images\n","â”‚Â Â  â”œâ”€â”€ frame_0001.png\n","â”‚Â Â  â”œâ”€â”€ frame_0002.png\n","â”‚Â Â  â”œâ”€â”€ .\n","â”‚Â Â  â”œâ”€â”€ .\n","â”‚Â Â  â”œâ”€â”€ .\n","â”‚Â Â  â””â”€â”€ frame_0100.png\n","â”œâ”€â”€ input\n","â”‚Â Â  â”œâ”€â”€ distorted\n","â”‚Â Â  â”‚Â Â  â””â”€â”€ sparse\n","â”‚Â Â  â”œâ”€â”€ frame_0001.png\n","â”‚Â Â  â”œâ”€â”€ frame_0002.png\n","â”‚Â Â  â”œâ”€â”€ .\n","â”‚Â Â  â”œâ”€â”€ .\n","â”‚Â Â  â”œâ”€â”€ .\n","â”‚Â Â  â””â”€â”€ frame_0100.png\n","â”œâ”€â”€ run-colmap-geometric.sh\n","â”œâ”€â”€ run-colmap-photometric.sh\n","â”œâ”€â”€ sparse\n","â”‚Â Â  â””â”€â”€ 0\n","â”‚Â Â      â”œâ”€â”€ cameras.bin\n","â”‚Â Â      â”œâ”€â”€ images.bin\n","â”‚Â Â      â””â”€â”€ points3D.bin\n","â””â”€â”€ stereo\n","    â”œâ”€â”€ consistency_graphs\n","    â”œâ”€â”€ depth_maps\n","    â”œâ”€â”€ fusion.cfg\n","    â”œâ”€â”€ normal_maps\n","    â””â”€â”€ patch-match.cfg\n","   ```\n","\n","1. **Upload data to Google Drive**  \n","   * From the `dataset` folder, upload the `images/` and `sparse/` directories to Google Drive. Make sure to keep both of them at the same location.\n","   * The folders can be uploaded as a `.zip` for faster uploading, and then unzip later in the notebook before using the dataset.\n","\n","1. Run the cells below.\n","\n","---\n","\n"],"metadata":{"id":"HQ71cQ5sfEk8"}},{"cell_type":"markdown","source":["## Mount the drive to access the data uploaded there"],"metadata":{"id":"sZ0tEBt_qwvV"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"sVRGu_M1qt2N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Unzipping\n","Run this cell only if you have uploaded the folders as zip and want to unzip them otherwise skip this cell."],"metadata":{"id":"PjUxaKfJ83IA"}},{"cell_type":"code","source":["# !unzip \"/content/drive/MyDrive/3DVSS_25/3DGS/images.zip\" -d \"/content/drive/MyDrive/3DVSS_25/3DGS\"\n","# !unzip \"/content/drive/MyDrive/3DVSS_25/3DGS/sparse.zip\" -d \"/content/drive/MyDrive/3DVSS_25/3DGS\""],"metadata":{"id":"Wn6P0ncm52O-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Cloning the Gaussian Splatting GitHub repository"],"metadata":{"id":"VoWA5abPd8CX"}},{"cell_type":"code","source":["%cd /content\n","!git clone --recursive https://github.com/camenduru/gaussian-splatting\n","!pip install -q plyfile"],"metadata":{"id":"ZhoM8T5zeDHt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","12. **Open the side panel** in your code editor to view the project directory structure.\n","13. **Navigate to** the following path:\n","\n","    ```\n","    gaussian-splatting/submodules/simple-knn\n","    ```\n","14. **Double-click** on the file named `simple_knn.cu`. It should open in the text editor on the right panel.\n","15. **Add the following line** at the top of the file along with the other `#include` statements:\n","\n","    ```cpp\n","    #include <float.h>\n","    ```\n","press `ctrl + s` or `cmd + s` to save the file and then close it.\n","---"],"metadata":{"id":"wCpqU2SKpWKO"}},{"cell_type":"markdown","source":["## Build the wheels for submodule dependencies\n","\n","> In Python, a **wheel** is a built-package format with the `.whl` extension. It's essentially a pre-built **binary distribution** of a Python package that makes installation faster and easier compared to building from source. Wheels eliminate the need to compile code during installation, which is especially useful for packages with complex dependencies or native C/C++ extensions."],"metadata":{"id":"961VluInePyZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"VjYy0F2gZIPR"},"outputs":[],"source":["%cd /content/gaussian-splatting\n","!pip install -q /content/gaussian-splatting/submodules/diff-gaussian-rasterization\n","!pip install -q /content/gaussian-splatting/submodules/simple-knn"]},{"cell_type":"markdown","source":["## Select Parameters"],"metadata":{"id":"A-99xj7yeUA8"}},{"cell_type":"code","source":["# @markdown Give absolute path to the location in your drive where the `images` and `sparse` folders are saved.\n","data_path=\"/content/drive/MyDrive/3DVSS_25/3DGS\" # @param {type: 'string'}\n","\n","# @markdown More the number of iterations better will be the constructed 3D scene.\n","iterations = 7000 # @param {type: 'integer'}\n","\n","# @markdown **Note**: Training for 7000 iterations will take around 15 mins"],"metadata":{"cellView":"form","id":"7ZW8skPIeH_0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python train.py -s \"$data_path\" --iterations \"$iterations\""],"metadata":{"id":"xGrCKB1CsNMo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Visualisation"],"metadata":{"id":"0-vUtONrvvQ-"}},{"cell_type":"markdown","source":["---\n","16. **After training completes**, navigate to the following directory:\n","\n","```\n","/content/gaussian-splatting/output/random_name/point_cloud/iteration_<n_iterations>\n","```\n","Download the `point_cloud.ply` file from there.  \n","**Note**: The randomly generated name of the output folder can be found in the information printed above during training.\n","\n","\n","**Visualise the output**: To visualize the generated `.ply` file follow these steps:\n","\n","17. Visit: [https://niujinshuchong.github.io/mip-splatting-demo/](https://niujinshuchong.github.io/mip-splatting-demo/)\n","\n","18. Scroll down to the **file upload section**.\n","\n","19. Upload your `.ply` file generated from training.\n","\n","20. Set the following visualization parameters:\n","\n","    ```text\n","    Minimum alpha   : 1  \n","    Camera up       : 0, -1, 0  \n","    Camera position : 0, 1, 0  \n","    Camera look-at  : 1, 0, 0\n","    ```\n","\n","21. Click on **`View`** to render and explore your 3D scene! ðŸ˜„\n","---"],"metadata":{"id":"ptL6pPxNtN6S"}}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1yj93B_Q1YH_NQ_tEYrsWj-h5R6BeGT41","timestamp":1750933225827},{"file_id":"https://github.com/camenduru/gaussian-splatting-colab/blob/main/gaussian_splatting_colab.ipynb","timestamp":1750911625099}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}