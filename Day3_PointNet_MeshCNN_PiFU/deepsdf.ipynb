{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1HCzauXN32dLHwO7CZvM3wVfi1k2FSdu8","timestamp":1754803941515}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"oontvxBg__1s"},"outputs":[],"source":["!gdown --id 1L2_InO7XjjZtlBDDfzz2v3uCPodwucmJ\n","!unzip DeepSDF.zip"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"XmCVCc7_S0sh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"id":"tEDqG_twBBRe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install trimesh"],"metadata":{"id":"4NP9BIUKBMks"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pysdf"],"metadata":{"id":"T6Phmop3RFF-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install plyfile"],"metadata":{"id":"wPv43pYqRdoc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Implicit Function (Signed Distance Function)\n","   "],"metadata":{"id":"Ye6MgiFwK-dN"}},{"cell_type":"markdown","source":["#### What is an Implicit Function?\n","\n","An implicit function defines a shape by a condition on $(x, y)$, such as $f(x, y) = 0$. For a circle of radius $r$ centered at $(x_0, y_0)$, the implicit equation is:\n","\n","$$x^2 + y^2 - r^2 = 0$$\n","\n","The Signed Distance Function (SDF) gives the shortest distance from any point $(x, y)$ to the circle's boundary, with the sign indicating inside (negative), on (zero), or outside (positive) the circle."],"metadata":{"id":"SZRTZu6fLBlS"}},{"cell_type":"code","source":["!pip install ipympl\n","get_ipython().kernel.do_shutdown(restart=True)\n","\n"],"metadata":{"id":"CoqTAFl9NosO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/DeepSDF"],"metadata":{"id":"61a27-FZAgMx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import ipywidgets as widgets\n","# from matplotlib.widgets import Slider\n","# %matplotlib widget\n"],"metadata":{"id":"_ebAXQKBK74N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Defining the Circle's Signed Distance Function (SDF)\n","The SDF for a circle centered at $(0, 0)$ with radius $r$ is:\n","\n","$$f(x, y) = \\sqrt{x^2 + y^2} - r$$"],"metadata":{"id":"g5FQV66YLKEV"}},{"cell_type":"code","source":["def circle_sdf(x, y, r, a=0.2, k=6):\n","    return np.sqrt(x**2 + y**2) - r"],"metadata":{"id":"6ImXgwxrLNNd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Setting up the Grid\n","\n","We'll create a grid of $(x, y)$ points to evaluate and visualize the SDF."],"metadata":{"id":"Kqi2EQNfLgzy"}},{"cell_type":"code","source":["grid_size = 400\n","x = np.linspace(-2, 2, grid_size)\n","y = np.linspace(-2, 2, grid_size)\n","X, Y = np.meshgrid(x, y)"],"metadata":{"id":"d2VhRdn3LQ5V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Visualizing the SDF with an Interactive Slider\n","\n","The plot below shows the SDF as a color map. The black contour represents the circle (where SDF = 0). Use the slider to change the radius and see how the SDF and the circle change.\n","    \n","- **Blue/Red colors**: Indicate the signed distance.\n","- **Black contour**: The actual circle boundary.\n","- **Colorbar**: Shows what the colors mean (signed distance values)."],"metadata":{"id":"Q8IDNktELloG"}},{"cell_type":"code","source":["from google.colab import output\n","output.enable_custom_widget_manager()"],"metadata":{"id":"hJdJBWicO-_1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set up the interactive plotting function\n","def update(radius=1.0):\n","    Z = circle_sdf(X, Y, radius)\n","\n","    fig, ax = plt.subplots(figsize=(6, 5))\n","\n","    cmap = ax.imshow(Z, extent=[-2, 2, -2, 2], origin='lower', cmap='coolwarm', alpha=0.8)\n","    cbar = fig.colorbar(cmap, ax=ax, fraction=0.046, pad=0.04)\n","    cbar.set_label('Signed Distance')\n","\n","    contour = ax.contour(X, Y, Z, levels=[0], colors='black')\n","\n","    ax.set_title(f'Circle SDF Visualization (Radius={radius:.2f})')\n","    ax.set_xlabel('x')\n","    ax.set_ylabel('y')\n","\n","    plt.show()\n","\n","# Create an ipywidget slider for radius\n","radius_slider = widgets.FloatSlider(\n","    value=1.0,\n","    min=0.1,\n","    max=1.9,\n","    step=0.01,\n","    description='Radius:',\n","    continuous_update=False\n",")\n","\n","# Bind the slider to the update function\n","ui = widgets.HBox([radius_slider])\n","out = widgets.interactive_output(update, {'radius': radius_slider})\n","\n","display(ui, out)"],"metadata":{"id":"MDGXNLOTQnKu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def ameoba_sdf(x, y, r, a=0.2, k=6):\n","    theta = np.arctan2(y, x)\n","    r = r + a * np.sin(k * theta)\n","    return np.sqrt(x**2 + y**2) - r\n"],"metadata":{"id":"B1runRzNLq9E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set up the interactive plotting function\n","def update(radius=1.0):\n","    Z = ameoba_sdf(X, Y, radius)\n","\n","    fig, ax = plt.subplots(figsize=(6, 5))\n","\n","    cmap = ax.imshow(Z, extent=[-2, 2, -2, 2], origin='lower', cmap='coolwarm', alpha=0.8)\n","    cbar = fig.colorbar(cmap, ax=ax, fraction=0.046, pad=0.04)\n","    cbar.set_label('Signed Distance')\n","\n","    contour = ax.contour(X, Y, Z, levels=[0], colors='black')\n","\n","    ax.set_title(f'Circle SDF Visualization (Radius={radius:.2f})')\n","    ax.set_xlabel('x')\n","    ax.set_ylabel('y')\n","\n","    plt.show()\n","\n","# Create an ipywidget slider for radius\n","radius_slider = widgets.FloatSlider(\n","    value=1.0,\n","    min=0.1,\n","    max=1.9,\n","    step=0.01,\n","    description='Radius:',\n","    continuous_update=False\n",")\n","\n","# Bind the slider to the update function\n","ui = widgets.HBox([radius_slider])\n","out = widgets.interactive_output(update, {'radius': radius_slider})\n","\n","display(ui, out)"],"metadata":{"id":"LW3aFctkLsCN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Meshes"],"metadata":{"id":"aKslF0BYLv0g"}},{"cell_type":"code","source":["import trimesh\n","mesh_path = 'data/armadillo.obj'\n","scene = trimesh.scene.Scene()\n","scene.add_geometry(trimesh.load(mesh_path))\n","scene.show()"],"metadata":{"id":"isaldzPSLyAm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Siren"],"metadata":{"id":"jAB0BAAcMNt_"}},{"cell_type":"code","source":["\n","import sys\n","import os\n","\n","from torch.utils.data import DataLoader, Dataset\n","import torch\n","import numpy as np\n","import trimesh\n","import pysdf\n","import torch.nn as nn\n","from tqdm.autonotebook import tqdm\n"],"metadata":{"id":"BKj4keeVL1Wz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"Extract mesh from an already optimised latent code and network.\n","Store the mesh in the same folder where the latent code is located.\"\"\"\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"],"metadata":{"id":"rh9vXkUEL4-v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","class MeshSDF(Dataset):\n","    def __init__(self, mesh_path='data/armadillo.obj', size=100, num_samples=2**16 ):\n","        super().__init__()\n","\n","        print(\"Loading point cloud\")\n","\n","        self.mesh = trimesh.load(mesh_path)\n","        print(\"Finished loading point cloud\")\n","        self.normals = self.mesh.vertex_normals\n","\n","        self.sdf_fn = pysdf.SDF(self.mesh.vertices, self.mesh.faces)\n","\n","        self.num_samples = num_samples\n","        assert self.num_samples % 8 == 0, \"num_samples must be divisible by 8.\"\n","\n","        self.size = size\n","\n","    def __len__(self):\n","        return self.size\n","\n","\n","    def __getitem__(self, idx):\n","\n","        sdfs = np.zeros((self.num_samples, 1))\n","\n","        # surface\n","        points_surface = self.mesh.sample(self.num_samples * 7 // 8)\n","        # perturb surface\n","        points_surface[self.num_samples // 2:] += 0.05 * np.random.randn(self.num_samples * 3 // 8, 3)\n","        # random\n","        points_uniform = np.random.rand(self.num_samples // 8, 3) * 2 - 1\n","        points = np.concatenate([points_surface, points_uniform], axis=0).astype(np.float32)\n","\n","        sdfs[self.num_samples // 2:] = -self.sdf_fn(points[self.num_samples // 2:])[:,None].astype(np.float32)\n","\n","\n","        coords = torch.from_numpy(points).float()\n","        return coords, torch.from_numpy(sdfs).float(), torch.from_numpy(self.normals).float()\n","\n","\n"],"metadata":{"id":"pknzRi-7L6bQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#define dataloader\n","sdf_dataset = MeshSDF()\n","dataloader = DataLoader(sdf_dataset, shuffle=True, batch_size=1, pin_memory=True, num_workers=0)\n"],"metadata":{"id":"3OW5CXKbL9aP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SineLayer(nn.Module):\n","    def __init__(self, in_features, out_features, bias=True, is_first=False, omega_0=30.):\n","        super().__init__()\n","        self.omega_0 = omega_0\n","        self.is_first = is_first\n","        self.in_features = in_features\n","        self.linear = nn.Linear(in_features, out_features, bias=bias)\n","        self.init_weights()\n","\n","\n","    def init_weights(self):\n","        with torch.no_grad():\n","            if self.is_first:\n","                self.linear.weight.uniform_(-1 / self.in_features, 1 / self.in_features)\n","            else:\n","                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, np.sqrt(6 / self.in_features) / self.omega_0)\n","\n","    def forward(self, input):\n","        return torch.sin(self.omega_0 * self.linear(input))\n","\n","class Siren(nn.Module):\n","    def __init__(self,in_features=3, hidden_features=256, hidden_layers=3, out_features=3, outermost_linear=True, first_omega_0=30., hidden_omega_0=30.):\n","        super().__init__()\n","\n","        self.net = []\n","        self.net.append(SineLayer(in_features, hidden_features, is_first=True, omega_0=first_omega_0))\n","\n","        for i in range(hidden_layers):\n","            self.net.append(SineLayer(hidden_features, hidden_features, is_first=False, omega_0=hidden_omega_0))\n","\n","        if outermost_linear:\n","            final_linear = nn.Linear(hidden_features, out_features)\n","            with torch.no_grad():\n","                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0, np.sqrt(6 / hidden_features) / hidden_omega_0)\n","            self.net.append(final_linear)\n","        else:\n","            self.net.append(SineLayer(hidden_features, out_features, is_first=False, omega_0=hidden_omega_0))\n","        self.net = nn.Sequential(*self.net)\n","\n","    def forward(self, coords):\n","        output = self.net(coords)\n","        return output\n"],"metadata":{"id":"YY4R1Pg8MBDo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Siren(in_features=3, out_features=1)\n","model.to(device)\n","optimizer = torch.optim.Adam(lr=1e-4, params=model.parameters())\n"],"metadata":{"id":"F2if3gUcMDQe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def train(model, optimizer, train_dataloader):\n","\n","    root_path = os.path.join('./siren_sdf')\n","    summaries_dir = os.path.join(root_path, 'summaries')\n","    checkpoints_dir = os.path.join(root_path, 'checkpoints')\n","    os.makedirs(root_path, exist_ok=True)\n","    os.makedirs(summaries_dir, exist_ok=True)\n","    os.makedirs(checkpoints_dir, exist_ok=True)\n","\n","\n","    epochs = 10000\n","    epochs_til_checkpoint = 1000\n","\n","    total_steps = 0\n","    losses = { loss:[] for loss in ['loss']}\n","\n","\n","    with tqdm(total=len(train_dataloader) * epochs) as pbar:\n","        train_losses = []\n","\n","        for epoch in range(epochs):\n","            if not epoch % epochs_til_checkpoint and epoch:\n","                torch.save(model.state_dict(),os.path.join(checkpoints_dir, 'model_epoch_%04d.pth' % epoch))\n","\n","            for step, data in enumerate(train_dataloader):\n","\n","                coords, gt_sdf, gt_normals = data[0],data[1],data[2]\n","                coords, gt_sdf, gt_normals = coords.to(device), gt_sdf.to(device), gt_normals.to(device)\n","\n","\n","                pred = model(coords)\n","\n","\n","                difference = (pred - gt_sdf).abs()\n","                scale = 1 / (gt_sdf.abs() + 1e-2)\n","                loss = difference * scale\n","                train_loss = loss.mean()\n","\n","                log_train_loss = train_loss.detach().item()\n","\n","\n","                losses['loss'].append(log_train_loss)\n","                train_losses.append(train_loss.item())\n","\n","                optimizer.zero_grad()\n","                train_loss.backward()\n","\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.)\n","                optimizer.step()\n","\n","                if not total_steps % epochs_til_checkpoint:\n","                    tqdm.write(\"Epoch %d, Train loss %0.6f\" % (epoch, log_train_loss))\n","                    torch.save(model.state_dict(),os.path.join(checkpoints_dir, 'model_current.pth'))\n","\n","                pbar.update(1)\n","\n","                total_steps += 1\n","\n","        torch.save(model.state_dict(),os.path.join(checkpoints_dir, 'model_final.pth'))\n","\n","\n"],"metadata":{"id":"wcRSH5h2ME1a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train(model, optimizer,dataloader)\n"],"metadata":{"id":"14WHgOpiMGe6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import sdf_meshing\n","model = Siren(in_features=3, out_features=1)\n","model.to(device)\n","\n","model.load_state_dict(torch.load('checkpoints/siren.pth'))\n","\n","mesh_path = 'siren_sdf/recon'\n","siren_mesh = sdf_meshing.create_mesh(model, filename=mesh_path, N=256)\n","scene = trimesh.scene.Scene()\n","scene.add_geometry(trimesh.load(mesh_path+'.ply'))\n","scene.show()\n"],"metadata":{"id":"DWbggpB0MIdi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## DeepSDF"],"metadata":{"id":"zbDzwdagMLHO"}},{"cell_type":"code","source":["import torch\n","import os\n","import model.model_sdf as sdf_model\n","from utils import utils_deepsdf\n","import trimesh\n","from results import runs_sdf\n","import results\n","import numpy as np\n","import config_files\n","import yaml"],"metadata":{"id":"QNKYk2ykAvSt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"Extract mesh from an already optimised latent code and network.\n","Store the mesh in the same folder where the latent code is located.\"\"\"\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"],"metadata":{"id":"FR-97EQXA4HY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def read_params(cfg):\n","    \"\"\"Read the settings from the settings.yaml file. These are the settings used during training.\"\"\"\n","    training_settings_path = os.path.join('results/runs_sdf',  cfg['folder_sdf'], 'settings.yaml')\n","    with open(training_settings_path, 'rb') as f:\n","        training_settings = yaml.load(f, Loader=yaml.FullLoader)\n","\n","    return training_settings\n"],"metadata":{"id":"09odCsKHA7HB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def reconstruct_object(cfg, latent_code, obj_idx, model, coords_batches, grad_size_axis):\n","    \"\"\"\n","    Reconstruct the object from the latent code and save the mesh.\n","    Meshes are stored as .obj files under the same folder cerated during training, for example:\n","    - runs_sdf/<datetime>/meshes_training/mesh_0.obj\n","    \"\"\"\n","    sdf = utils_deepsdf.predict_sdf(latent_code, coords_batches, model)\n","    try:\n","        vertices, faces = utils_deepsdf.extract_mesh(grad_size_axis, sdf)\n","    except:\n","        print('Mesh extraction failed')\n","        return\n","\n","    # save mesh as obj\n","    mesh_dir = os.path.join('results/runs_sdf',  cfg['folder_sdf'], 'meshes_training')\n","    if not os.path.exists(mesh_dir):\n","        os.mkdir(mesh_dir)\n","    obj_path = os.path.join(mesh_dir, f\"mesh_{obj_idx}.obj\")\n","    trimesh.exchange.export.export_mesh(trimesh.Trimesh(vertices, faces), obj_path, file_type='obj')\n","\n"],"metadata":{"id":"0SKVNIIUA8ch"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cfg_path = os.path.join(os.path.dirname(config_files.__file__), 'reconstruct_from_latent.yaml')\n","with open(cfg_path, 'rb') as f:\n","    cfg = yaml.load(f, Loader=yaml.FullLoader)\n","\n","\n","training_settings = read_params(cfg)\n","\n","# Load the model\n","weights = os.path.join('results/runs_sdf',  cfg['folder_sdf'], 'weights.pt')\n","\n","model = sdf_model.SDFModel(\n","    num_layers=training_settings['num_layers'],\n","    skip_connections=training_settings['latent_size'],\n","    latent_size=training_settings['latent_size'],\n","    inner_dim=training_settings['inner_dim']).to(device)\n","model.load_state_dict(torch.load(weights, map_location=device))\n","\n","# Extract mesh obtained with the latent code optimised at inference\n","coords, grad_size_axis = utils_deepsdf.get_volume_coords(cfg['resolution'])\n","coords = coords.to(device)\n","\n","# Split coords into batches because of memory limitations\n","coords_batches = torch.split(coords, 100000)\n","\n","# Load paths\n","str2int_path = os.path.join(os.path.dirname(results.__file__), 'idx_str2int_dict.npy')\n","results_dict_path = os.path.join('results/runs_sdf',  cfg['folder_sdf'], 'results.npy')\n","\n","# Load dictionaries\n","str2int_dict = np.load(str2int_path, allow_pickle=True).item()\n","results_dict = np.load(results_dict_path, allow_pickle=True).item()\n","\n","for obj_id_path in cfg['obj_ids']:\n","    # Get object index in the results dictionary\n","    obj_idx = str2int_dict[obj_id_path]  # index in collected latent vector\n","    # Get the latent code optimised during training\n","    latent_code = results_dict['best_latent_codes'][obj_idx]\n","    latent_code = torch.tensor(latent_code).to(device)\n","    reconstruct_object(cfg, latent_code, obj_idx, model, coords_batches, grad_size_axis)\n"],"metadata":{"id":"hQ9GVcQQA-BZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scene = trimesh.scene.Scene()\n","scene.add_geometry(trimesh.load('results/runs_sdf/17_07_172540/meshes_training/mesh_1.obj'))\n","scene.show()"],"metadata":{"id":"sw5472bUA_YF"},"execution_count":null,"outputs":[]}]}